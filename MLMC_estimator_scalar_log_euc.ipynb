{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SÃ©ance 2 : MLMC log euclidiann estimator (scalar version)\n",
    "\n",
    "We want to implement in python the MLMC log euclidian estimator of the variance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "First, let's code our functions, and our variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "d = 10\n",
    "\n",
    "#print(np.random.uniform(-1,1,d))\n",
    "v_1= np.array([-0.18268292, -0.63730044,  0.49158538, -0.51712638, -0.90171302,  0.40921266,  0.63791406,  0.70701292, -0.24888679,  0.94455888])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define f\n",
    "\n",
    "def f(X,v):\n",
    "    return v.T@X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7436679237968549\n"
     ]
    }
   ],
   "source": [
    "# Testing f\n",
    "X = np.random.standard_normal(10)\n",
    "print(f(X,v_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's estimate the expectation and the variance of $f(X)$ for several $X_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "X = np.random.standard_normal((d,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_vec(X,v):\n",
    "    \"\"\"\n",
    "    X : (d,n) matrix\n",
    "    v : d vector \n",
    "    \"\"\"\n",
    "    return v.T@X\n",
    "\n",
    "def f_vec_squared(X,v):\n",
    "    \"\"\"\n",
    "    X : (d,n) matrix\n",
    "    v : d vector \n",
    "    \"\"\"\n",
    "    return (v.T@X)**2\n",
    "\n",
    "exp_var = np.sum(np.square(v_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation =  0.4120209097680835\n",
      "Variance =  3.6628589711714157\n",
      "Expected variance (sum of v_i^2) =  3.7900798793633337\n"
     ]
    }
   ],
   "source": [
    "# Estimation of the expecation and the variance :\n",
    "E_MC = np.mean(f_vec(X,v_1))\n",
    "Var_MC = np.mean(f_vec_squared(X,v_1))\n",
    "print(\"Expectation = \", E_MC)\n",
    "print(\"Variance = \", Var_MC)\n",
    "print(\"Expected variance (sum of v_i^2) = \", exp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For n = 100, we are quite good with the standard MC method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLMC estimation\n",
    "We still have $(X_n)_{n\\in\\mathbb{N}} \\in \\mathbb{R}^d$ a sequence of random variables i.i.d following the normal distribution $\\mathcal{N}_d(0,1)$. \n",
    "\n",
    "We still have $v_1 \\in \\mathbb{R}^d$ for our function $f_1$ (previous $f$). We now have a low fidelity function $f_0$ based on the high fidelity function $f_1$ with $v_0 = v_1 + \\varepsilon$, with $\\varepsilon \\sim \\mathcal{N}_d(0_d,\\sigma^2 I_d)$ and $\\sigma^2 = 0.01$ or $0.1$. \n",
    "\n",
    "We now have :\n",
    "\n",
    "\n",
    "We have aswell for the variance : \n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\mathbb{V}}\\left( f_1(X) \\right) &= \\mathbb{E}\\left[ f_1(X)^2 \\right] \\\\\n",
    "& \\approx exp\\left( log\\left( \\frac{1}{n_0} \\sum_{k=1}^{n_0} f_0(X^{(k,0)})^2 \\right) + \\left[ log\\left(\\frac{1}{n_1} \\sum_{k=1}^{n_1}f_1(X^{(k,1)})^2  \\right) - log\\left( \\frac{1}{n_1} \\sum_{k=1}^{n_1} f_0(X^{(k,1)})^2 \\right) \\right] \\right) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "Let's code our variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample size n = 100\n"
     ]
    }
   ],
   "source": [
    "d = 10 # lenght of random vectors\n",
    "print(\"sample size n =\", n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.random.normal(0,0.01,d)\n",
    "# print(eps)\n",
    "\n",
    "v_0 = v_1 + eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 100\n",
    "n1 = 10\n",
    "X1 = np.random.standard_normal((d,n1))\n",
    "X0 = np.random.standard_normal((d,n0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E_MLMC = 0.10017623769720468\n"
     ]
    }
   ],
   "source": [
    "# Calcul de E_MLMC\n",
    "Y1_1 = f_vec(X1,v_1)\n",
    "Y1_0 = f_vec(X1,v_0)\n",
    "Y0_0 = f_vec(X0,v_0)\n",
    "E_MLMC = np.mean(Y0_0) + np.mean(Y1_1-Y1_0)\n",
    "print(\"E_MLMC =\", E_MLMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Var_MLMC_log = 3.719383569318339\n"
     ]
    }
   ],
   "source": [
    "# Calcul de Var_MLMC\n",
    "#  3.7900798793633337\n",
    "Y0_0_squared = f_vec_squared(X0,v_0)\n",
    "Y1_0_squared = f_vec_squared(X1,v_0)\n",
    "Y1_1_squared = f_vec_squared(X1,v_1)\n",
    "Var_MLMC_log = np.exp(np.log(np.mean(Y0_0_squared)) + np.log(np.mean(Y1_1_squared))-np.log(np.mean(Y1_0_squared)))\n",
    "print(\"Var_MLMC_log =\", Var_MLMC_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on the Var_MC = 3.3566814484471728 %\n",
      "Error on the Var_MLMC = 1.8652986822238327 %\n"
     ]
    }
   ],
   "source": [
    "# Comparaison \n",
    "Err_Var_MC = np.abs(Var_MC-exp_var)/exp_var * 100\n",
    "Err_Var_MLMC_log = np.abs(Var_MLMC_log-exp_var)/exp_var * 100\n",
    "\n",
    "print(\"Error on the Var_MC =\",Err_Var_MC, \"%\\nError on the Var_MLMC =\", Err_Var_MLMC_log,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
