{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostque de l'estimateur \n",
    "\n",
    "Le but de cette partie est se rendre compte de la fiabilité de l'estimateur de la variance en MLMC en calculant sa variance. On comparera les résultats à celle de l'estimateur classique MC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calcul des estimateurs MLMC et MLMC log euclidien \n",
    "On se place dans la cas fidélité 2. Nos donnés sont des vecteurs gaussiens centrés réduits de dimension d.\n",
    "formule de la variance: \n",
    " \n",
    "$\\hat{\\mathbb{V}}\\left( f_1(X) \\right) = \\mathbb{E}\\left[ f_1(X)^2 \\right] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_vec(X,v):\n",
    "    return v.T@X\n",
    "\n",
    "def f_vec_squared(X,v):\n",
    "    return (v.T@X)**2\n",
    "\n",
    "d = 10 # lenght of random vectors\n",
    "\n",
    "v_1= np.array([-0.00606533, -0.02837768, -0.20481078, -0.05524456,  0.00408442, -0.02378791, -0.11289296, -0.09047946, -0.0828985,   0.01015773])\n",
    "# eps = np.random.normal(0,0.001,d) \n",
    "# v_0 = v_1 + eps  #vecteur ceof basse fidélité \n",
    "# print(v_0)\n",
    "# v_0 = np.array([-0.00589986, -0.02848255, -0.2058163,  -0.05332501,  0.00356343, -0.02399142, -0.11355733, -0.08986586, -0.08302782,  0.0085727 ])\n",
    "v_0 = np.array([-0.04775578, -0.02158142, -0.22861181,  0.00999135 , 0.05261623, -0.03810132, -0.08892537, -0.09858141, -0.06851002,  0.09957945])\n",
    "exp_var = np.sum(np.square(v_1))\n",
    "\n",
    "print(exp_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_var_MLMC(n0,n1):\n",
    "    X1 = np.random.standard_normal((d,n1))\n",
    "    X0 = np.random.standard_normal((d,n0))\n",
    "\n",
    "    # #estimateur de l'espérence\n",
    "    # Y1_1 = f_vec(X1,v_1)\n",
    "    # Y1_0 = f_vec(X1,v_0)\n",
    "    # Y0_0 = f_vec(X0,v_0)\n",
    "    # E_MLMC = np.mean(Y0_0) + np.mean(Y1_1-Y1_0)\n",
    "\n",
    "    #estimateur de la variance \n",
    "    Y0_0_squared = f_vec_squared(X0,v_0)\n",
    "    Y1_0_squared = f_vec_squared(X1,v_0)\n",
    "    Y1_1_squared = f_vec_squared(X1,v_1)\n",
    "    Var_MLMC = np.mean(Y0_0_squared) + np.mean(Y1_1_squared-Y1_0_squared)\n",
    "\n",
    "    return Var_MLMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_var_MLMC_log(n0,n1):\n",
    "    X1 = np.random.standard_normal((d,n1))\n",
    "    X0 = np.random.standard_normal((d,n0))\n",
    "\n",
    "    # #estimateur de l'espérence\n",
    "    # Y1_1 = f_vec(X1,v_1)\n",
    "    # Y1_0 = f_vec(X1,v_0)\n",
    "    # Y0_0 = f_vec(X0,v_0)\n",
    "    # E_MLMC = np.mean(Y0_0) + np.mean(Y1_1-Y1_0)\n",
    "\n",
    "    #estimateur de la variance \n",
    "    Y0_0_squared = f_vec_squared(X0,v_0)\n",
    "    Y1_0_squared = f_vec_squared(X1,v_0)\n",
    "    Y1_1_squared = f_vec_squared(X1,v_1)\n",
    "    Var_MLMC_log = np.exp(np.log(np.mean(Y0_0_squared)) + np.log(np.mean(Y1_1_squared))-np.log(np.mean(Y1_0_squared)))\n",
    "    return Var_MLMC_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance de ces estimateurs\n",
    "\n",
    "On calcul maintenant la variance des rélutats que nous donne cet estimateur pour n=100000 résultats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_est_var_MLMC(n):\n",
    "    n1=9\n",
    "    n0=16\n",
    "    tab_var=[]\n",
    "    tab_var_log =[]\n",
    "    for i in range(n):\n",
    "        tab_var.append(estim_var_MLMC(n0,n1))\n",
    "        tab_var_log.append(estim_var_MLMC_log(n0,n1))\n",
    "    return [np.var(tab_var),np.var(tab_var_log)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_var_MLMC(960,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estim_var_HF():\n",
    "#     d = 10 # lenght of random vectors\n",
    "\n",
    "\n",
    "#     X1 = np.random.standard_normal((d,150))\n",
    "#     Y1_1_squared=f_vec_squared(X1,v_1)\n",
    "#     return(np.var(Y1_1_squared))\n",
    "# print (estim_var_HF())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(var_est_var_MLMC(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##methode classique MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  var_est_var_MC(n):\n",
    "    tab_var=[]\n",
    "    d = 10\n",
    "    \n",
    "\n",
    "    for i in range(n):\n",
    "        X = np.random.standard_normal((d,20))\n",
    "        estim_var_MC=np.mean(f_vec_squared(X,v_1))\n",
    "        tab_var.append(estim_var_MC)\n",
    "    return (np.var(tab_var))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(var_est_var_MLMC(10000))\n",
    "print(var_est_var_MC(10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cas pathologiqe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def estim_var_MLMC_patho(n0,n1):\n",
    "#     X1 = np.random.standard_normal((d,n1))\n",
    "#     X0 = np.random.standard_normal((d,n0))\n",
    "\n",
    "#     #estimateur de l'espérence\n",
    "#     Y1_1 = f_vec(X1,v_1)\n",
    "#     Y1_0 = f_vec(X1,v_0)\n",
    "#     Y0_0 = f_vec(X0,v_0)\n",
    "#     E_MLMC = np.mean(Y0_0) + np.mean(Y1_1-Y1_0)\n",
    "\n",
    "#     #estimateur de la variance \n",
    "#     Y0_0_squared = f_vec_squared(X0,v_0)\n",
    "#     Y1_0_squared = f_vec_squared(X1,v_0)\n",
    "#     Y1_1_squared = f_vec_squared(X1,v_1)\n",
    "#     mean = np.mean(Y1_1_squared-Y1_0_squared) #qu'est ce qui doit etre neg ? \n",
    "#     if mean < 0:\n",
    "#         Var_MLMC = np.mean(Y0_0_squared) + mean\n",
    "#         Var_MLMC_log = np.exp(np.log(np.mean(Y0_0_squared)) + np.log(np.mean(Y1_1_squared))-np.log(np.mean(Y1_0_squared)))\n",
    "#         return [Var_MLMC, Var_MLMC_log]\n",
    "#     else :\n",
    "#         return 'a'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_var_MLMC_patho(n0,n1):\n",
    "    X1 = np.random.standard_normal((d,n1))\n",
    "    X0 = np.random.standard_normal((d,n0))\n",
    "\n",
    "    #estimateur de l'espérence\n",
    "    Y1_1 = f_vec(X1,v_1)\n",
    "    Y1_0 = f_vec(X1,v_0)\n",
    "    Y0_0 = f_vec(X0,v_0)\n",
    "    E_MLMC = np.mean(Y0_0) + np.mean(Y1_1-Y1_0)\n",
    "\n",
    "    #estimateur de la variance \n",
    "    Y0_0_squared = f_vec_squared(X0,v_0)\n",
    "    Y1_0_squared = f_vec_squared(X1,v_0)\n",
    "    Y1_1_squared = f_vec_squared(X1,v_1)\n",
    "    Var_MLMC = np.mean(Y0_0_squared) + np.mean(Y1_1_squared-Y1_0_squared) #qu'est ce qui doit etre neg ? \n",
    "    if Var_MLMC < 0:\n",
    "        Var_MLMC_log = np.exp(np.log(np.mean(Y0_0_squared)) + np.log(np.mean(Y1_1_squared))-np.log(np.mean(Y1_0_squared)))\n",
    "        return [Var_MLMC, Var_MLMC_log]\n",
    "    else :\n",
    "        return 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_var_MLMC_patho(n0,n1):\n",
    "    \"\"\"\n",
    "    Modified from the previous one. Takes into account the correction on the variance.\n",
    "    \"\"\"\n",
    "    X1 = np.random.standard_normal((d,n1))\n",
    "    X0 = np.random.standard_normal((d,n0))\n",
    "\n",
    "    #estimateur de la variance\n",
    "    Y1_1 = f_vec(X1,v_1)\n",
    "    Y1_0 = f_vec(X1,v_0)\n",
    "    Y0_0 = f_vec(X0,v_0)\n",
    "\n",
    "    #estimateur de la variance \n",
    "    Y0_0_squared = f_vec_squared(X0,v_0)\n",
    "    Y1_0_squared = f_vec_squared(X1,v_0)\n",
    "    Y1_1_squared = f_vec_squared(X1,v_1)\n",
    "    Var_MLMC = np.var(Y0_0, ddof=1) + np.var(Y1_1, ddof=1) - np.var(Y1_0, ddof=1) #qu'est ce qui doit etre neg ? \n",
    "    if Var_MLMC < 0:\n",
    "        Var_MLMC_log = np.exp(np.log(np.var(Y0_0, ddof=1)) + np.log(np.var(Y1_1, ddof=1))-np.log(np.var(Y1_0,  ddof=1)))\n",
    "        return [Var_MLMC, Var_MLMC_log]\n",
    "    else :\n",
    "        return 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_est_var_MLMC_patho(n):\n",
    "    \"\"\"\n",
    "    Returns all pathological cases when Var_MLMC from estim_var_MLMC_patho is negative\n",
    "\n",
    "    Return : two arrays, \n",
    "    \"\"\"\n",
    "    n1=9\n",
    "    n0=16\n",
    "    tab_var=[]\n",
    "    tab_var_log =[]\n",
    "    for _ in range(n):\n",
    "        estim_var_patho = estim_var_MLMC_patho(n0,n1)\n",
    "        if estim_var_patho != 'a' :\n",
    "            tab_var.append(estim_var_patho[0])\n",
    "            tab_var_log.append(estim_var_patho[1])\n",
    "\n",
    "    print(\"Nombre de cas patho = \", len(tab_var))\n",
    "    return tab_var,tab_var_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_var,tab_var_log = var_est_var_MLMC_patho(10000)\n",
    "\n",
    "tab_var\n",
    "tab_var_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tab_var_MLMC(n):\n",
    "    n0=16\n",
    "    n1=9\n",
    "    tab_var=[]\n",
    "    tab_var_log =[]\n",
    "    for i in range(n):\n",
    "        tab_var.append(estim_var_MLMC(n0,n1))\n",
    "        tab_var_log.append(estim_var_MLMC_log(n0,n1))\n",
    "    return [tab_var,tab_var_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "Tab_var_MLMC,Tab_var_MLMC_log = tab_var_MLMC(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tab_var_MLMC[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tab_var_MLMC_log[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias_log = np.mean(Tab_var_MLMC_log) - exp_var\n",
    "bias = np.mean(Tab_var_MLMC) - exp_var\n",
    "\n",
    "# Regarder le biais (car censé être non biaisé)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Bias_log, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.var(Tab_var_MLMC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance et biais en fonction du budget\n",
    "\n",
    "Tracer en fonction du budget :\n",
    "- Variance ML\n",
    "- Biais ML\n",
    "- Variance LML\n",
    "- Biais LML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def M_ell(eta, V_ell, C_ell,S_L, m=0):\n",
    "#     \"\"\"\n",
    "#     eta : budget\n",
    "#     V_ell : tableau contenant [V_0,V_1,...,V_L]\n",
    "#     C_ell : tableau contenant [C_0,C_1,...,C_L]\n",
    "\n",
    "#     return : la formule M_ell au dessus qui nous donne le nombre d'élement optimal à simuler\n",
    "#     \"\"\"\n",
    "    \n",
    "#     return m + 1 + np.floor(\n",
    "#         (eta_tilde/S_L)*np.sqrt(V_ell[ell]/C_ell[ell])\n",
    "#     )\n",
    "\n",
    "def M_ell_tab(eta, V_ell, C_ell,m=0):\n",
    "    \"\"\"\n",
    "    eta : budget\n",
    "    V_ell : tableau contenant [V_0,V_1,...,V_L]\n",
    "    C_ell : tableau contenant [C_0,C_1,...,C_L]\n",
    "\n",
    "    return : la formule M_ell au dessus qui nous donne le nombre d'élement optimal à simuler\n",
    "    \"\"\"\n",
    "    eta_tilde = eta # - m*np.sum(...)\n",
    "    S_L = np.sum(np.sqrt(np.multiply(V_ell,C_ell)))\n",
    "\n",
    "    return m + 1 + np.floor(\n",
    "        (eta_tilde/S_L)*np.sqrt(V_ell*1/C_ell)\n",
    "    )\n",
    "\n",
    "def tab_var_MLMC_bis(n,M_0,M_1):\n",
    "    tab_var=[]\n",
    "    tab_var_log =[]\n",
    "    for _ in range(n):\n",
    "        tab_var.append(estim_var_MLMC(M_0,M_1))\n",
    "        tab_var_log.append(estim_var_MLMC_log(M_0,M_1))\n",
    "    return [tab_var,tab_var_log]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "X = np.random.standard_normal((d,N))\n",
    "V_0 = np.var(f_vec_squared(X,v_0))\n",
    "V_1 = np.var(f_vec_squared(X,v_1) - f_vec_squared(X,v_0))\n",
    "\n",
    "V_ell = np.array([V_0,V_1])\n",
    "C_ell = np.array([0.75,1.])\n",
    "\n",
    "print(M_ell_tab(20, V_ell, C_ell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_eta = np.logspace(1,4,10)\n",
    "print(budget_eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_tab = []\n",
    "var_MLMC_tab = []\n",
    "bias_log_tab = []\n",
    "var_MLMC_log_tab = []\n",
    "\n",
    "N=10000\n",
    "\n",
    "for eta in tqdm(budget_eta):\n",
    "    M_0,M_1 = map(int, M_ell_tab(eta,V_ell,C_ell))\n",
    "    Tab_var_MLMC,Tab_var_MLMC_log = tab_var_MLMC_bis(N,M_0,M_1)\n",
    "    \n",
    "    # Construction des tableaux de variance\n",
    "    var_MLMC_tab.append(np.var(Tab_var_MLMC))\n",
    "    var_MLMC_log_tab.append(np.var(Tab_var_MLMC_log))\n",
    "\n",
    "    # Construction des tableaux de biais\n",
    "    bias_log_tab.append(np.abs(np.mean(Tab_var_MLMC_log) - exp_var))\n",
    "    bias_tab.append(np.abs(np.mean(Tab_var_MLMC) - exp_var))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot log-log\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot des données\n",
    "plt.loglog(budget_eta, bias_tab, marker='o', label='Biais Tab')\n",
    "plt.loglog(budget_eta, var_MLMC_tab, marker='s', label='Var MLMC Tab')\n",
    "plt.loglog(budget_eta, bias_log_tab, marker='^', label='Biais Log Tab')\n",
    "plt.loglog(budget_eta, var_MLMC_log_tab, marker='x', label='Var MLMC Log Tab')\n",
    "\n",
    "# Ajouter titre et légendes\n",
    "plt.title('Graphique Log-Log')\n",
    "plt.xlabel('Budget eta')\n",
    "plt.ylabel('Valeurs')\n",
    "plt.legend()\n",
    "\n",
    "# Afficher le plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
