{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "cp.fuse(np.float32)\n",
    "h = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v= cp.array([-0.00606533, -0.02837768, -0.20481078, -0.05524456,  0.00408442, -0.02378791, -0.11289296, -0.09047946, -0.0828985,   0.01015773]) # Real life\n",
    "v_0 = cp.array([-0.26251362, -0.22397083, -0.28459696, -0.14160629,  0.11507459,\n",
    "       -0.01314795,  0.00368215, -0.2233519 , -0.0494188 , -0.09833207])\n",
    "v_0 = cp.array([ 1.02602951,  1.59187996,  0.23337749, -0.62634188,  0.16052645,\n",
    "       -0.47135837,  0.21609987,  0.45909724,  0.70707697, -0.76436048])\n",
    "v_1 = cp.array([-0.09152057,  0.26501426, -0.26361748, -0.09584528,  0.07564258,\n",
    "       -0.28932995, -0.15172387, -0.17311338, -0.02250007, -0.02662765])\n",
    "v_2 = cp.array([ 0.02806491,  0.18164134, -0.02569311,  0.08406244,  0.09760685,\n",
    "       -0.2754576 , -0.18692242,  0.05429335, -0.05959692, -0.16104073])\n",
    "v_3 = cp.array([ 0.00719622, -0.01367537, -0.04378771,  0.15642576,  0.03295938,\n",
    "       -0.1364489 , -0.02709714, -0.16822205, -0.15617831, -0.05832736])\n",
    "\n",
    "v_array = [v_0, v_1, v_2, v_3]\n",
    "exp_var = cp.sum(cp.square(v))\n",
    "def expected_var(v):\n",
    "    return cp.sum(cp.square(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating vectors to have a variance close to the real one v\n",
    "eps = 7e-1\n",
    "v_generated = v - cp.random.normal(0,eps,len(v))\n",
    "print(cp.linalg.norm(expected_var(v_generated) - expected_var(v)))\n",
    "v_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable & functions def: \n",
    "def f_vec(X,v):\n",
    "    return v.T@X\n",
    "\n",
    "def f_vec_squared(X,v):\n",
    "    return (v.T@X)**2\n",
    "\n",
    "d = 10 # lenght of random vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estim_var_MLMC(N,M):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - N: Number of samples for each Y_ell (howw much we generate Y to compute one variance)\n",
    "    - M: array with sample lengh of each level [M_0,...,M_L] (how much variances we generate)\n",
    "\n",
    "    \"\"\"\n",
    "    # Variance at level 0\n",
    "    X_M_ell = cp.random.standard_normal((N,d,M[0]))\n",
    "    Y_ell_M_ell = f_vec(X_M_ell,v_0)\n",
    "    Var_MLMC = cp.var(Y_ell_M_ell, axis=1, ddof=1)\n",
    "    \n",
    "    # Loop on M to have correction V^(ell)_{M_ell}(Y_ell) - V^(ell)_{M_ell}(Y_{ell-1})\n",
    "    for ell in range(1,len(M)):\n",
    "        X_M_ell = cp.random.standard_normal((N,d,M[ell]))\n",
    "        Y_ell_M_ell = f_vec(X_M_ell,v_array[ell])\n",
    "        Y_ell_M_ell_minus_1 = f_vec(X_M_ell,v_array[ell-1])\n",
    "        Var_MLMC += cp.var(Y_ell_M_ell, axis=1, ddof=1) - cp.var(Y_ell_M_ell_minus_1, axis=1, ddof=1)\n",
    "\n",
    "    return Var_MLMC\n",
    "\n",
    "def estim_var_MLMC_log(N,M):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - N: Number of samples for each Y_ell (howw much we generate Y to compute one variance)\n",
    "    - M: array with sample lengh of each level [M_0,...,M_L] (how much variances we generate)\n",
    "\n",
    "    \"\"\"\n",
    "    # Variance at level 0\n",
    "    X_M_ell = cp.random.standard_normal((N,d,M[0]))\n",
    "    Y_ell_M_ell = f_vec(X_M_ell,v_0)\n",
    "    Var_log_MLMC = cp.log(cp.var(Y_ell_M_ell, axis=1, ddof=1))\n",
    "    \n",
    "    # Loop on M to have correction V^(ell)_{M_ell}(Y_ell) - V^(ell)_{M_ell}(Y_{ell-1})\n",
    "    for ell in range(1,len(M)):\n",
    "        X_M_ell = cp.random.standard_normal((N,d,M[ell]))\n",
    "        Y_ell_M_ell = f_vec(X_M_ell,v_array[ell])\n",
    "        Y_ell_M_ell_minus_1 = f_vec(X_M_ell,v_array[ell-1])\n",
    "        Var_log_MLMC += np.log(cp.var(Y_ell_M_ell, axis=1, ddof=1)) - cp.log(cp.var(Y_ell_M_ell_minus_1, axis=1, ddof=1))\n",
    "\n",
    "    return cp.exp(Var_log_MLMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000000\n",
    "M = [18]\n",
    "X_M_ell = cp.random.standard_normal((N,d,M[0]))\n",
    "Y_ell_M_ell_squared = f_vec_squared(X_M_ell,v)\n",
    "Y_ell_M_ell = f_vec(X_M_ell,v)\n",
    "\n",
    "print(cp.mean(Y_ell_M_ell))\n",
    "\n",
    "print(\"Var en calculant avec cp.var (ddof = 1) =\", cp.var(Y_ell_M_ell, axis=1, ddof=1))\n",
    "print(\"Var en calculant avec cp.var + correction =\", M[0]/(M[0]-1)*cp.var(Y_ell_M_ell, axis=1))\n",
    "print(\"var en calculant à la main la somme =\", cp.sum(Y_ell_M_ell_squared, axis=1)/(M[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M_ell_tab(eta, V_ell, C_ell,m=0):\n",
    "    \"\"\"\n",
    "    eta : budget\n",
    "    V_ell : tableau contenant [V_0,V_1,...,V_L]\n",
    "    C_ell : tableau contenant [C_0,C_1,...,C_L]\n",
    "\n",
    "    return : la formule M_ell au dessus qui nous donne le nombre d'élement optimal à simuler\n",
    "    \"\"\"\n",
    "    eta_tilde = eta # - m*cp.sum(...)\n",
    "    S_L = (cp.sqrt(cp.multiply(V_ell,C_ell))).sum()\n",
    "\n",
    "    return m + 1 + cp.floor(\n",
    "        (eta_tilde/S_L)*cp.sqrt(V_ell*1/C_ell)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_pilote = 10000\n",
    "X = cp.random.standard_normal((d,N_pilote))\n",
    "V = [cp.var(f_vec_squared(X,v_0))]\n",
    "for i in range(1,len(v_array)):\n",
    "    V.extend([cp.var(f_vec_squared(X,v_array[i]) - f_vec_squared(X,v_array[i-1]))])\n",
    "\n",
    "V_ell = cp.array(V)\n",
    "C_ell = cp.array([.25,0.5,0.75,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10000\n",
    "budget_eta = np.logspace(1,4,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_tab = []\n",
    "var_MLMC_tab = []\n",
    "bias_log_tab = []\n",
    "var_MLMC_log_tab = []\n",
    "\n",
    "\n",
    "for eta in tqdm(budget_eta):\n",
    "    # Pour chaque budget eta, calcul de nos M_0 et M_1\n",
    "    M = list(map(int,M_ell_tab(eta,V_ell,C_ell)))\n",
    "    \n",
    "    # Calcul de nos tableaux de nos estimateurs de taille N\n",
    "    Tab_var_MLMC = estim_var_MLMC(N,M)\n",
    "    var_MLMC_tab.append(cp.var(Tab_var_MLMC))\n",
    "    bias_tab.append(cp.square(cp.mean(Tab_var_MLMC) - expected_var(v)))\n",
    "\n",
    "    Tab_var_MLMC = None\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    Tab_var_MLMC_log = estim_var_MLMC_log(N,M)\n",
    "    var_MLMC_log_tab.append(cp.var(Tab_var_MLMC_log))\n",
    "    bias_log_tab.append(cp.square(cp.mean(Tab_var_MLMC_log) - expected_var(v)))\n",
    "\n",
    "    Tab_var_MLMC_log = None\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "var_MLMC_tab = [x.item() for x in var_MLMC_tab]\n",
    "bias_tab = [x.item() for x in bias_tab]\n",
    "\n",
    "var_MLMC_log_tab = [x.item() for x in var_MLMC_log_tab]\n",
    "bias_log_tab = [x.item() for x in bias_log_tab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot log-log\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot des données\n",
    "plt.loglog(budget_eta, bias_tab, marker='o', label='MSE MLMC')\n",
    "plt.loglog(budget_eta, var_MLMC_tab, marker='s', label='Var MLMC')\n",
    "plt.loglog(budget_eta, bias_log_tab, marker='^', label='MSE Log-MLMC')\n",
    "plt.loglog(budget_eta, var_MLMC_log_tab, marker='x', label='Var Log-MLMC')\n",
    "\n",
    "\n",
    "# Ajouter titre et légendes\n",
    "plt.title(f'MSE et variance en fonction du budget pour n={n}')\n",
    "plt.xlabel('Budget eta')\n",
    "plt.ylabel('MSE/Variance')\n",
    "plt.legend()\n",
    "\n",
    "# Afficher le plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE en fonction de n\n",
    "budget fixé à $10^3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_eta_int = 1e3\n",
    "samples_N = list(map(int,np.logspace(2,5,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_tab = []\n",
    "var_MLMC_tab = []\n",
    "bias_log_tab = []\n",
    "var_MLMC_log_tab = []\n",
    "\n",
    "\n",
    "for N in tqdm(samples_N):\n",
    "    # Pour chaque budget eta, calcul de nos M_0 et M_1\n",
    "    M = list(map(int,M_ell_tab(eta,V_ell,C_ell)))\n",
    "    \n",
    "    # Calcul de nos tableaux de nos estimateurs de taille N\n",
    "    Tab_var_MLMC = estim_var_MLMC(N,M)\n",
    "    var_MLMC_tab.append(cp.var(Tab_var_MLMC))\n",
    "    bias_tab.append(cp.square(cp.mean(Tab_var_MLMC) - expected_var(v)))\n",
    "\n",
    "    Tab_var_MLMC = None\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    Tab_var_MLMC_log = estim_var_MLMC_log(N,M)\n",
    "    var_MLMC_log_tab.append(cp.var(Tab_var_MLMC_log))\n",
    "    bias_log_tab.append(cp.square(cp.mean(Tab_var_MLMC_log) - expected_var(v)))\n",
    "\n",
    "    Tab_var_MLMC_log = None\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "var_MLMC_tab = [x.item() for x in var_MLMC_tab]\n",
    "bias_tab = [x.item() for x in bias_tab]\n",
    "\n",
    "var_MLMC_log_tab = [x.item() for x in var_MLMC_log_tab]\n",
    "bias_log_tab = [x.item() for x in bias_log_tab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet4A",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
